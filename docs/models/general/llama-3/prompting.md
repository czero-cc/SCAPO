# llama-3 Prompting Guide

*Last updated: 2025-08-14*

## Tips & Techniques

- Set temperature to 0.7 - temperature 0.7
- Set top_p to 0.95 - top_p 0.95
- Set steps to 50 - steps 50
- Set cfg to 7 - cfg 7
- Use system prompt - include a system prompt to guide the model
- Chain of thought - prompt the model to think step-by-step
- Few-shot examples - provide a few examples in the prompt
- Use streaming for slow responses - enable streaming to reduce latency
- Batch requests to reduce cost - send multiple requests in one batch

## Sources

- Reddit community discussions
- User-reported experiences

# ğŸ§˜ Stay Calm and Prompt On (SCAPO)

<div align="center">

![Don't Be This Guy](assets/guy_freaking_out1.png)

**The Zen Guide to AI Model Best Practices**

[![Made with Love](https://img.shields.io/badge/Made%20with-â¤ï¸-red.svg)](https://github.com/fiefworks/scapo)
[![No API Keys](https://img.shields.io/badge/API%20Keys-Not%20Required-brightgreen.svg)]()
[![LLM Powered](https://img.shields.io/badge/LLM-Powered-blue.svg)]()
[![Browser Magic](https://img.shields.io/badge/Scraping-Browser%20Based-orange.svg)]()
[![MCP Ready](https://img.shields.io/badge/Claude-MCP%20Ready-purple.svg)]()
[![PRs Welcome](https://img.shields.io/badge/PRs-Welcome-brightgreen.svg)](CONTRIBUTING.md)

### ğŸ¯ Stop freaking out about prompts. We got you.

</div>

## ğŸ¤” What is SCAPO?

Ever found yourself like this when trying to get AI to work?

![Classic AI Frustration](assets/guy_freaking_out2.png)

**SCAPO** (Stay Calm and Prompt On) is your zen master for AI model best practices. We automatically scrape, analyze, and organize prompting wisdom from across the internet - so you don't have to.

## âœ¨ Features That'll Make You Say "Finally!"

- ğŸ•·ï¸ **Intelligent Browser Scraping** - No API keys. No BS. Just pure browser automation magic.
- ğŸ§  **LLM-Powered Extraction** - Your selected LLMs read the internet so you don't have to.
- ğŸ¯ **Automatic Categorization** - Text, image, video, audio models all organized nicely.
- ğŸ”Œ **Claude Desktop Integration** - MCP server that just worksâ„¢ï¸
- ğŸš€ **Zero Config** - Literally just run it. We're not kidding.

## ğŸƒâ€â™‚ï¸ Quick Start (60 Seconds or Less)

### 1. Clone & Install
```bash
git clone https://github.com/czero-cc/scapo.git
cd scapo
curl -LsSf https://astral.sh/uv/install.sh | sh  # Install uv
uv venv && source .venv/bin/activate
uv pip install -r requirements.txt
uv run playwright install
```

### 2. Configure Your Local LLM
```bash
cp .env.example .env
# Edit .env - just point to your LM Studio (localhost:1234)
```

### 3. Scrape Some Wisdom
```bash
python -m src.cli scrape run --sources reddit:LocalLLaMA
# Remember: Be respectful! Don't run too many requests at once.
```

### 4. Use with Claude Desktop
```bash
npx @sota-practices/mcp-server  # That's it. Seriously.
```

## ğŸ¨ The SCAPO Philosophy

```
1. No API keys required (we're rebels like that)
2. Community wisdom > Corporate docs (for GenAI, yes!)
3. If it's not automatic, it's not worth it
4. Browser scraping > API begging
5. Be respectful when scraping - don't hammer servers
```

## ğŸ› ï¸ How It Works (The Magic Behind the Calm)

### 1. ğŸ•¸ï¸ Intelligent Scraping
We use Playwright to browse the web like a human (but faster):
- Reddit discussions
- Hacker News debates
- GitHub repositories
- Any public forum

### 2. ğŸ§  Two-Stage LLM Processing
```python
# Stage 1: "Is this even about AI?"
entities = extract_entities_with_llm(content)
if not entities.is_ai_related:
    return  # Skip the crypto shills

# Stage 2: "What can we learn?"
practices = extract_best_practices(content, entities)
```

### 3. ğŸ“ Smart Organization
```
models/
â”œâ”€â”€ text/
â”‚   â”œâ”€â”€ Qwen3-Coder-Flash/
â”‚   â”‚   â”œâ”€â”€ prompting.md      # "Use XML tags for structure"
â”‚   â”‚   â”œâ”€â”€ parameters.json   # {"temperature": 0.2}
â”‚   â”‚   â””â”€â”€ pitfalls.md      # "Don't set temp too high"
â”œâ”€â”€ image/
â”‚   â””â”€â”€ stable-diffusion-xl/
â””â”€â”€ video/
    â””â”€â”€ runway-gen3/
```

## ğŸ® MCP Server for Claude Desktop

### Installation (One Line!)
```json
{
  "mcpServers": {
    "scapo": {
      "command": "npx",
      "args": ["@sota-practices/mcp-server"],
      "env": {
        "SOTA_MODELS_PATH": "/path/to/scapo/models"
      }
    }
  }
}
```

### What You Can Ask Claude
- "What are the best practices for Qwen3-Coder?"
- "Search for models good at coding"
- "List all available image models"
- "Recommend models for creative writing"

## ğŸŒŸ Real Examples from the Wild

### Found on Reddit
```markdown
## Qwen3-Coder-Flash Prompting

"Discovered this today - XML tags are GAME CHANGING for code:
<task>implement binary search</task>
<requirements>
- Use type hints
- Add docstring
- O(log n) complexity
</requirements>"

Confidence: 0.9
Source: reddit:LocalLLaMA
```

### Extracted from HackerNews
```json
{
  "model": "DeepCoder-14B",
  "practice_type": "parameter",
  "content": "Set repetition_penalty to 1.15 for less repetitive code",
  "confidence": 0.85
}
```

## ğŸ“Š Stats That Matter

- ğŸ” **Sources Monitored**: Reddit, HN, GitHub (more coming!)
- ğŸ¤– **Models Tracked**: 50+ and growing daily
- ğŸ“ˆ **Practices Extracted**: 1000+ actionable tips
- âš¡ **Processing Time**: ~2s per post with local LLM

## ğŸš€ Advanced Usage

### Custom Sources
```python
# Add your own scraper in intelligent_browser_scraper.py
async def scrape_mycommunity_browser(self, page: Page):
    await page.goto("https://mycommunity.com")
    # Your scraping logic here
```

### Batch Processing
```bash
# Scrape multiple sources
python -m src.cli scrape run \
  --sources reddit:LocalLLaMA,reddit:OpenAI,hackernews \
  --limit 20
```

### Export Practices
```bash
# Coming soon: Export to your favorite format
python -m src.cli export --format obsidian --model gpt-4
```

## ğŸ¤ Contributing

We're building the Wikipedia of AI prompting. Join us!

### Easy Contributions
1. ğŸ”— **Add a Source** - Know a great AI community? Add it!
2. ğŸ’¡ **Share a Practice** - Found a killer prompt? Share it!
3. ğŸ› **Report Issues** - Something broken? Let us know!
4. â­ **Star the Repo** - Spread the calm!

### Dev Setup
```bash
make install  # Set everything up
make test     # Run tests
make scrape   # Test scraping
```

## ğŸ¯ Things We Might Do Later

- [ ] YouTube transcript extraction
- [ ] Discord server monitoring
- [ ] Real-time practice updates
- [ ] Practice voting system
- [ ] Chrome extension
- [ ] VS Code integration

## ğŸ“œ License

MIT - Because sharing is caring. 

(Yeah, anyways our CZero engine needed similar stuff so we just created this. Enjoy! ğŸ¤·)

## ğŸ™ Acknowledgments

- The open source AI/LLM communities for blazing the trail
- The r/LocalLLaMA community for being awesome
- LM Studio & Ollama for making local LLMs accessible
- OpenRouter for cloud AI serving
- Claude for the MCP protocol
- Coffee â˜• for making this possible

---

<div align="center">

### Remember: Stay Calm and Prompt On ğŸ§˜

**Built with â¤ï¸ by The [CZero Engine](https://czero.cc) Team**

<img src="assets/fiefworks_cropped.png" alt="Fiefworks, Inc." width="120" style="margin: 20px 0;"/>

[Contact](mailto:info@czero.cc) â€¢ [CZero](https://czero.cc)

</div>
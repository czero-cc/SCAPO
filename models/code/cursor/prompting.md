# Cursor Prompting Guide

*Last updated: 2025-08-12*

## Technical Tips

- Enable prompt caching in Cursor to reduce API costs; the deepseekcoderâ€‘v2 model is noted to be cheaper than other models.

## Usage Tips

- Use the free Meta Llama models available in Cursor: meta-llama/llama-3.1-405b-instruct, meta-llama/llama-3.2-90b-vision-instruct, meta-llama/llama-3.1-70b-instruct.
- Run any AI model (e.g., GROQ or local models) in Cursor by setting up a proxy server; use the R1SONQWEN implementation for a working example.

## Sources

- Reddit community discussions
- User-reported experiences
